{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-MNA-DS11",
      "language": "python",
      "name": "u4-s3-mna-ds11"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "LS_DSPT8_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKCCs_73QfNX"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SaGcxvmpx_R"
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, SpatialDropout1D\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import requests\n",
        "import os\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:18:20.442Z",
          "iopub.execute_input": "2020-06-15T18:18:20.453Z",
          "iopub.status.idle": "2020-06-15T18:18:20.513Z",
          "shell.execute_reply": "2020-06-15T18:18:20.523Z"
        },
        "id": "kbZ45D2KQfNY"
      },
      "source": [
        "import requests\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:25:49.778Z",
          "iopub.execute_input": "2020-06-15T18:25:49.781Z",
          "iopub.status.idle": "2020-06-15T18:25:51.467Z",
          "shell.execute_reply": "2020-06-15T18:25:51.469Z"
        },
        "id": "kYq_XrX8QfNc"
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = r.apparent_encoding\n",
        "data = r.text\n",
        "data = data.split('\\r\\n')\n",
        "toc = [l.strip() for l in data[44:130:2]]\n",
        "# Skip the Table of Contents\n",
        "data = data[135:]\n",
        "\n",
        "# Fixing Titles\n",
        "toc[9] = 'THE LIFE OF KING HENRY V'\n",
        "toc[18] = 'MACBETH'\n",
        "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
        "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
        "\n",
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
        "\n",
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "\n",
        "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
        "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
        "df_toc.loc[42, 'end'] = len(data)\n",
        "df_toc['end'] = df_toc['end'].astype('int')\n",
        "\n",
        "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-06-15T18:26:12.630Z",
          "iopub.execute_input": "2020-06-15T18:26:12.637Z",
          "iopub.status.idle": "2020-06-15T18:26:12.643Z",
          "shell.execute_reply": "2020-06-15T18:26:12.647Z"
        },
        "id": "6ggXk8XNQfNm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0f03caaa-0bad-487d-b2e1-26568dbfcd77"
      },
      "source": [
        "# Shakespeare Data Parsed by Play\n",
        "df_toc.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "      <td>-99</td>\n",
              "      <td>14379</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "      <td>14380</td>\n",
              "      <td>17171</td>\n",
              "      <td>AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "      <td>17172</td>\n",
              "      <td>20372</td>\n",
              "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
              "      <td>20373</td>\n",
              "      <td>30346</td>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CYMBELINE</td>\n",
              "      <td>30347</td>\n",
              "      <td>30364</td>\n",
              "      <td>CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 title  ...                                               text\n",
              "0  THE TRAGEDY OF ANTONY AND CLEOPATRA  ...                                                   \n",
              "1                       AS YOU LIKE IT  ...  AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...\n",
              "2                 THE COMEDY OF ERRORS  ...  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...\n",
              "3            THE TRAGEDY OF CORIOLANUS  ...  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...\n",
              "4                            CYMBELINE  ...  CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ia1_Kktm3aB"
      },
      "source": [
        "# divide b/w plays and sonets\n",
        "sonets = data[:2776]\n",
        "plays = data[2777:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcV-w2iUm4le",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "60e0ec3d-e3ce-42b5-e6eb-dff226b8fb12"
      },
      "source": [
        "data[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'From fairest creatures we desire increase,'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXAQW0Q6m_ej"
      },
      "source": [
        "def long_lines(lst_ln):\n",
        "    clean = []\n",
        "    \n",
        "    for ln in lst_ln: \n",
        "        \n",
        "        if len(ln) == 0:\n",
        "            pass\n",
        "        else:\n",
        "            pct = len(ln.strip(' ')) / len(ln)\n",
        "\n",
        "            if pct >= .5:\n",
        "                clean.append(ln.lstrip())\n",
        "\n",
        "    return clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRW2Jy3cnhor"
      },
      "source": [
        "sonets = long_lines(sonets)\n",
        "plays = long_lines(plays)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5xdknlXmrQ6"
      },
      "source": [
        "#### Word Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZXeZmvomgA1"
      },
      "source": [
        "vocab = list(set(\"\\r\\n\".join(plays).split()))\n",
        "words = [line.split() for line in plays]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzJa_G-_nmnM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b000f78b-3a86-415b-be07-cdfbb93e2c81"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75578"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7wlAr1XnpzQ"
      },
      "source": [
        "#### Character Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlMkitqwnrhd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf5c89f6-fe33-4b57-ae7f-75abe2babccf"
      },
      "source": [
        "text = '\\r\\n'.join(sonets)\n",
        "\n",
        "chars = list(set(text))\n",
        "\n",
        "char_int = {c: i for i,c in enumerate(chars)}\n",
        "int_char = {i:c for i,c in enumerate(chars)}\n",
        "\n",
        "print(f\"Our corpus contains {len(chars)} unique characters.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our corpus contains 63 unique characters.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCz81ZoNoGWS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e232129e-612c-4084-df04-da593b1d995c"
      },
      "source": [
        "# Create the Sequence Data\n",
        "\n",
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Each element is 40 characters long\n",
        "next_chars = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_chars.append(encoded[i + maxlen])\n",
        "\n",
        "print('sequences:', len(sequences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences: 19163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4pxB4kVooXN"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Specify x & y\n",
        "\n",
        "X = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_chars[i]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkNFxY8apK0w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6c971d6-8fb8-4664-e715-554059024253"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19163, 40, 63)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ynxbyndpOii"
      },
      "source": [
        "# Build the model: a single LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars)), dropout=0.2))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='nadam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DIj-k5cp49z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c879c9e7-0469-4aae-cb7e-09b4004dd19a"
      },
      "source": [
        "model.summary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Model.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f0b8377d400>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlQ1Fl4Tp8x-"
      },
      "source": [
        "def sample(preds):\n",
        "  # Helper function to sample an index from a probability array\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / 1\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MubS3Rx4qXa4"
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "\n",
        "    print()\n",
        "    print('------ Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen -1)\n",
        "\n",
        "    generated = ''\n",
        "\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "\n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "\n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "\n",
        "        sentence = sentence[1:] + next_char\n",
        "\n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tm-X9rmromy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "18519a7d-78f3-4a1f-bbfd-a32531a17fa2"
      },
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "model.fit(\n",
        "    X, y,\n",
        "    batch_size=1024,\n",
        "    validation_split=.2,\n",
        "    epochs=10,\n",
        "    callbacks=[\n",
        "        print_callback, \n",
        "        EarlyStopping(min_delta=.02, monitor='val_loss', patience=10),\n",
        "        tensorboard_callback,\n",
        "    ],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.1428\n",
            "------ Generating text after Epoch: 0\n",
            "----- Generating with seed: \"re mute.\n",
            "Or if they sing, ’tis with so \"\n",
            "re mute.\n",
            "Or if they sing, ’tis with so  aia  huwtg tdry\n",
            "lda t wlss tiAeehsieas ou bneisdvrhtd wwksnhboty  ee nevnsuao oiti ed \n",
            "tdew h eettcrhihaisinpaey y tg,tre aeh invtvlorM\n",
            "i haolft, .tvehs htohies Irc’,sla\n",
            "wgre \n",
            " s tgvwei Olu t    lwhoc\n",
            " anybeue yhsbohIehgiy\n",
            " mdn h.s\n",
            "ubtetebiWIv nh im SHlell\n",
            "15/15 [==============================] - 33s 2s/step - loss: 3.1428 - val_loss: 3.1260\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.1421\n",
            "------ Generating text after Epoch: 1\n",
            "----- Generating with seed: \"n in disgrace with Fortune and men’s eye\"\n",
            "n in disgrace with Fortune and men’s eye osgccoes ogss r\n",
            "  Isdt hl   a hsi  hc eeeoa o mhO a anmhere.eessrb Bompbet\n",
            " tierAwarerght heetke a wvn e ma ieb\n",
            "mei\n",
            "e’ad   b nsg sewu otsh\n",
            "iv hbhw  ea. r\n",
            "me  i esflwrsbvNafnes hsosetd gfufae \n",
            "fal\n",
            "s,soe imegbenelINsrneh \n",
            "15/15 [==============================] - 32s 2s/step - loss: 3.1421 - val_loss: 3.1281\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.1419\n",
            "------ Generating text after Epoch: 2\n",
            "----- Generating with seed: \"to go about,\n",
            "Doth part his function, an\"\n",
            "to go about,\n",
            "ahn hu f s e etnohon,ev ho t tp ilkhl\n",
            "ergeoe iae  u  :,aeellor\n",
            " h\n",
            "tsr t y eiird\n",
            "useaesbc cyohf pto\n",
            "daoms.eb eoscsdc\n",
            "nvanltc nr s- gvlSt,osierntwPe,eoppw  osc?sfr s ,intphbnesmrton llrt nvWy e Aahwf\n",
            "aA rglh on   wrtvo.op\n",
            " B\n",
            "eee tt esl oh e\n",
            "pngi yemtauf  \n",
            "h,aw,t n l t bofye  e lie\n",
            "15/15 [==============================] - 33s 2s/step - loss: 3.1419 - val_loss: 3.1249\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.1421\n",
            "------ Generating text after Epoch: 3\n",
            "----- Generating with seed: \"would (I say) mine eyes be blessed made,\"\n",
            "would (I say) mine eyes be blessed made,onuniachysehayo e\n",
            "neeo etss ion eOpssh mh.nsss\n",
            "u eaih,egsnet ’ lnierwrwe m f tonego \n",
            " u lhsenorn.:LAruovh\n",
            "bsndoymsyrinaee ettn\n",
            "yih im \n",
            "j tser\n",
            "trl\n",
            "15/15 [==============================] - 32s 2s/step - loss: 3.1421 - val_loss: 3.1284\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.1431\n",
            "------ Generating text after Epoch: 4\n",
            "----- Generating with seed: \"my love’s breath? The purple pride\n",
            "Whic\"\n",
            "my love’s breath? The purple pride\n",
            "Whiciist\n",
            "a\n",
            " d\n",
            "os ys,\n",
            "she,b ecirtwiiseo hei sd   p\n",
            "t e    \n",
            " tt P’iede  ,b hraaas l ve\n",
            "oitdeoestuy e\n",
            "sreFnrp\n",
            "ctsey tieAl\n",
            "g xlmn ddv,t,ahrt,s b-tvdr,thiaefl h r e rei wsoaet riuepehuukh heufhoboimiotde dc eva  iih\n",
            "   \n",
            " WoveeTsewedayifnods \n",
            "g\n",
            "t’gt,  la\n",
            "15/15 [==============================] - 35s 2s/step - loss: 3.1431 - val_loss: 3.1257\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.1426\n",
            "------ Generating text after Epoch: 5\n",
            "----- Generating with seed: \" love thou usest,\n",
            "But yet be blamed, if\"\n",
            " love thou usest,\n",
            "But yet be blamed, ifBaas,po an oAntettoY oeSthsiW ogteet oot  l ndoufh\n",
            "fonitnhttn\n",
            " ef\n",
            "ym, toob ownha ras\n",
            " fo\n",
            "ohe\n",
            "\n",
            "h  ninhs,n ag eb’lociho\n",
            "n\n",
            "thsyiwooo \n",
            " \n",
            "l himwe l ra \n",
            "hsy goe    rwngey\n",
            "15/15 [==============================] - 32s 2s/step - loss: 3.1426 - val_loss: 3.1245\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.1424\n",
            "------ Generating text after Epoch: 6\n",
            "----- Generating with seed: \"with thee partake?\n",
            "Do I not think on th\"\n",
            "with thee partake?\n",
            "ee,noeune loabwts \n",
            "r\n",
            "m l nlnaoacW hn\n",
            "hohftnsl \n",
            "sne  ea,h edsd\n",
            "15/15 [==============================] - 34s 2s/step - loss: 3.1424 - val_loss: 3.1282\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.1415\n",
            "------ Generating text after Epoch: 7\n",
            "----- Generating with seed: \"lander’s mark was ever yet the fair,\n",
            "Th\"\n",
            "lander’s mark was ever yet the fair,\n",
            " n  tl ntun,griyr\n",
            " mgmm\n",
            "nreqnev lwT(h tohte,trtld  tneAfaerekb MpneiT\n",
            "l ioWelm et,gdetb\n",
            "ioloeogopo\n",
            "in,ic auc e eI csluoAtdp\n",
            "ltgemo, iea,hybemuwv ny sfhat g p gd mm,lhokonr,a M,hnva  l amfrmhpsbsrrr osrnpupc, r\n",
            "  p\n",
            "e seGjit T\n",
            "uecaitifuiaoeree,ehdaira.bda rh \n",
            "15/15 [==============================] - 32s 2s/step - loss: 3.1415 - val_loss: 3.1287\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.1415\n",
            "------ Generating text after Epoch: 8\n",
            "----- Generating with seed: \"ontent,\n",
            "Whereto th’ inviting time our f\"\n",
            "ontent,\n",
            "i s ee’hf hr et wpmottha sl sIDuat reabshbge   oo irgklonhrn,suWbIdb :e los uo te Bsteay\n",
            " mt hasy le ect csc\n",
            "feefhrstoph hytt hdhegoas.neeIiv  mw eluerct.lhde  apt\n",
            "uuadoeb  ke eaegreln n.hrttoo   rreum .e\n",
            "15/15 [==============================] - 32s 2s/step - loss: 3.1415 - val_loss: 3.1288\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.1416\n",
            "------ Generating text after Epoch: 9\n",
            "----- Generating with seed: \"hou shouldst depart,\n",
            "Leaving thee livin\"\n",
            "hou shouldst depart,\n",
            " eeIi oheeoh psjlheyeeowadrn(sednh endsd ,   urc Iaiyt\n",
            "uh ,depcfoiwpi,er noiciahgeOpoauhead f ed gnet as\n",
            "a\n",
            "sdv htpnuf nahl msi\n",
            " efh\n",
            "suAsirh ewh onina,d we anit me as\n",
            "e Ieclrv,w,emh  yyeoevw y a,uskhdohegil  ouihmrt alo  h Wkedseale-tlv k\n",
            "mews\n",
            "as   nkgs wbt\n",
            "vottrido\n",
            "15/15 [==============================] - 33s 2s/step - loss: 3.1416 - val_loss: 3.1258\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0b427f04a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-b7wPrgs5d5"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUVGrDags-TT"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}